# ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´ í™•ì¸ ì™„ì „ ê°€ì´ë“œ

í”„ë¡œì íŠ¸ì˜ PostgreSQL ë° Redis ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´ë¥¼ í™•ì¸í•˜ëŠ” ëª¨ë“  ë°©ë²•ì„ ì •ë¦¬í•œ ì¢…í•© ê°€ì´ë“œì…ë‹ˆë‹¤.

## ğŸ¯ í˜„ì¬ í”„ë¡œì íŠ¸ ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •

### PostgreSQL ì •ë³´
- **ë²„ì „**: PostgreSQL 16 Alpine
- **ì»¨í…Œì´ë„ˆëª…**: cp9_postgres
- **ë°ì´í„°ë² ì´ìŠ¤ëª…**: research_db
- **ì‚¬ìš©ì**: postgres
- **ë¹„ë°€ë²ˆí˜¸**: postgres
- **í¬íŠ¸**: 5432 (í˜¸ìŠ¤íŠ¸), 5432 (ì»¨í…Œì´ë„ˆ)
- **ì—°ê²° URL**: postgresql+asyncpg://postgres:postgres@localhost:5432/research_db

### Redis ì •ë³´
- **ë²„ì „**: Redis 7 Alpine
- **ì»¨í…Œì´ë„ˆëª…**: cp9_redis
- **í¬íŠ¸**: 6379 (í˜¸ìŠ¤íŠ¸), 6379 (ì»¨í…Œì´ë„ˆ)
- **ë°ì´í„°ë² ì´ìŠ¤ êµ¬ë¶„**:
  - DB 0: ì¼ë°˜ìš© (redis://localhost:6379/0)
  - DB 1: ìºì‹œìš© (redis://localhost:6379/1)
  - DB 2: Celery ë¸Œë¡œì»¤ (redis://localhost:6379/2)
  - DB 3: Celery ê²°ê³¼ ì €ì¥ (redis://localhost:6379/3)

## ğŸ–¥ï¸ 1. GUI ë„êµ¬ë¡œ í™•ì¸

### pgAdmin (ê¶Œì¥)
**ì ‘ì† ì •ë³´**
- URL: http://localhost:5050
- ì´ë©”ì¼: admin@example.com
- ë¹„ë°€ë²ˆí˜¸: admin

**ì„œë²„ ì—°ê²° ì¶”ê°€**
1. pgAdmin ì›¹ ì¸í„°í˜ì´ìŠ¤ ì ‘ì†
2. "Add New Server" í´ë¦­
3. ì—°ê²° ì •ë³´ ì…ë ¥:
   ```
   Name: Research Database
   Host: postgres (Docker ë„¤íŠ¸ì›Œí¬ ë‚´ì—ì„œ)
   ë˜ëŠ” host.docker.internal (Docker Desktop ì‚¬ìš© ì‹œ)
   Port: 5432
   Database: research_db
   Username: postgres
   Password: postgres
   ```

**í™•ì¸ ê°€ëŠ¥í•œ ì •ë³´**
- í…Œì´ë¸” ëª©ë¡ ë° ìŠ¤í‚¤ë§ˆ
- ë°ì´í„° ì¡°íšŒ ë° í¸ì§‘
- ì¿¼ë¦¬ ì‹¤í–‰ ê²°ê³¼
- ì¸ë±ìŠ¤ ë° ì œì•½ì¡°ê±´
- ì„±ëŠ¥ í†µê³„

### Redis Commander (ì„ íƒì‚¬í•­)
```bash
# Redis GUI ë„êµ¬ ì„¤ì¹˜ ë° ì‹¤í–‰
npm install -g redis-commander
redis-commander --redis-host localhost --redis-port 6379
# http://localhost:8081 ì ‘ì†
```

## ğŸ’» 2. ëª…ë ¹ì¤„ ë„êµ¬ë¡œ í™•ì¸

### PostgreSQL ëª…ë ¹ì¤„ ì ‘ê·¼

#### Docker ì»¨í…Œì´ë„ˆë¥¼ í†µí•œ ì ‘ê·¼
```bash
# ì»¨í…Œì´ë„ˆì— ì§ì ‘ ì ‘ì†
docker exec -it cp9_postgres bash

# PostgreSQL ì ‘ì†
docker exec -it cp9_postgres psql -U postgres -d research_db

# í•œ ì¤„ë¡œ ì‹¤í–‰
docker exec -it cp9_postgres psql -U postgres -d research_db -c "SELECT version();"
```

#### ë¡œì»¬ psql í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©
```bash
# PostgreSQL í´ë¼ì´ì–¸íŠ¸ ì„¤ì¹˜ í•„ìš”
psql -h localhost -p 5432 -U postgres -d research_db

# íŠ¹ì • ì¿¼ë¦¬ ì‹¤í–‰
psql -h localhost -p 5432 -U postgres -d research_db -c "\\dt"
```

### ê¸°ë³¸ PostgreSQL ëª…ë ¹ì–´

#### ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´ ì¡°íšŒ
```sql
-- ë²„ì „ í™•ì¸
SELECT version();

-- í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´
SELECT current_database(), current_user, current_schema();

-- ë°ì´í„°ë² ì´ìŠ¤ í¬ê¸°
SELECT pg_database_size(current_database());
SELECT pg_size_pretty(pg_database_size(current_database()));

-- ì—°ê²° ì •ë³´
SELECT * FROM pg_stat_activity WHERE datname = current_database();
```

#### í…Œì´ë¸” ë° ìŠ¤í‚¤ë§ˆ ì •ë³´
```sql
-- ëª¨ë“  í…Œì´ë¸” ëª©ë¡
\\dt

-- í…Œì´ë¸” ìƒì„¸ ì •ë³´
\\d+ table_name

-- ìŠ¤í‚¤ë§ˆ ëª©ë¡
\\dn

-- í…Œì´ë¸” í¬ê¸°
SELECT 
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size
FROM pg_tables 
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
```

#### í˜„ì¬ í”„ë¡œì íŠ¸ í…Œì´ë¸” ì¡°íšŒ
```sql
-- ë¦¬ì„œì¹˜ ê´€ë ¨ í…Œì´ë¸”
SELECT table_name, table_schema 
FROM information_schema.tables 
WHERE table_schema = 'public' 
  AND table_type = 'BASE TABLE';

-- í…Œì´ë¸”ë³„ ë ˆì½”ë“œ ìˆ˜
SELECT 
    schemaname,
    tablename,
    n_tup_ins as "inserts",
    n_tup_upd as "updates", 
    n_tup_del as "deletes",
    n_live_tup as "live_tuples",
    n_dead_tup as "dead_tuples"
FROM pg_stat_user_tables
ORDER BY n_live_tup DESC;
```

### Redis ëª…ë ¹ì¤„ ì ‘ê·¼

#### Redis CLI ì‚¬ìš©
```bash
# Redis ì»¨í…Œì´ë„ˆì— ì ‘ì†
docker exec -it cp9_redis redis-cli

# ë˜ëŠ” ë¡œì»¬ redis-cli ì‚¬ìš©
redis-cli -h localhost -p 6379

# íŠ¹ì • DB ì„ íƒ
redis-cli -h localhost -p 6379 -n 0
```

#### Redis ê¸°ë³¸ ëª…ë ¹ì–´
```redis
# ì„œë²„ ì •ë³´
INFO

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
INFO memory

# í‚¤ ê°œìˆ˜ (í˜„ì¬ DB)
DBSIZE

# ëª¨ë“  í‚¤ ëª©ë¡ (ì£¼ì˜: í”„ë¡œë•ì…˜ì—ì„œëŠ” ìœ„í—˜)
KEYS *

# íŠ¹ì • íŒ¨í„´ì˜ í‚¤
KEYS research:*

# DBë³„ í‚¤ ê°œìˆ˜ í™•ì¸
INFO keyspace

# ë°ì´í„°ë² ì´ìŠ¤ ë³€ê²½
SELECT 0  # ì¼ë°˜ìš©
SELECT 1  # ìºì‹œìš©
SELECT 2  # Celery ë¸Œë¡œì»¤
SELECT 3  # Celery ê²°ê³¼
```

## ğŸ 3. Python ì½”ë“œë¡œ í™•ì¸

### ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸
```python
# db_check.py
import asyncio
from sqlalchemy.ext.asyncio import create_async_engine
from sqlalchemy import text
from app.core.config import settings

async def check_database():
    """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë° ê¸°ë³¸ ì •ë³´ í™•ì¸"""
    engine = create_async_engine(str(settings.database_url))
    
    try:
        async with engine.connect() as conn:
            # ê¸°ë³¸ ì—°ê²° í…ŒìŠ¤íŠ¸
            result = await conn.execute(text("SELECT 1"))
            print("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ")
            
            # ë²„ì „ í™•ì¸
            result = await conn.execute(text("SELECT version()"))
            version = result.scalar()
            print(f"ğŸ“‹ PostgreSQL ë²„ì „: {version}")
            
            # í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´
            result = await conn.execute(text("""
                SELECT current_database() as db_name, 
                       current_user as user_name,
                       current_schema() as schema_name
            """))
            info = result.fetchone()
            print(f"ğŸ—„ï¸  ë°ì´í„°ë² ì´ìŠ¤: {info.db_name}")
            print(f"ğŸ‘¤ ì‚¬ìš©ì: {info.user_name}")
            print(f"ğŸ“‚ ìŠ¤í‚¤ë§ˆ: {info.schema_name}")
            
            # ë°ì´í„°ë² ì´ìŠ¤ í¬ê¸°
            result = await conn.execute(text("""
                SELECT pg_size_pretty(pg_database_size(current_database())) as db_size
            """))
            size = result.scalar()
            print(f"ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ í¬ê¸°: {size}")
            
    except Exception as e:
        print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
    
    finally:
        await engine.dispose()

if __name__ == "__main__":
    asyncio.run(check_database())
```

### í…Œì´ë¸” ì •ë³´ ì¡°íšŒ
```python
# table_info.py
import asyncio
from sqlalchemy.ext.asyncio import create_async_engine
from sqlalchemy import text
from app.core.config import settings

async def check_tables():
    """í…Œì´ë¸” ì •ë³´ ì¡°íšŒ"""
    engine = create_async_engine(str(settings.database_url))
    
    try:
        async with engine.connect() as conn:
            # í…Œì´ë¸” ëª©ë¡
            result = await conn.execute(text("""
                SELECT table_name, table_schema, table_type
                FROM information_schema.tables 
                WHERE table_schema = 'public'
                ORDER BY table_name
            """))
            
            tables = result.fetchall()
            print("ğŸ“Š í…Œì´ë¸” ëª©ë¡:")
            for table in tables:
                print(f"  - {table.table_name} ({table.table_type})")
            
            # í…Œì´ë¸”ë³„ ë ˆì½”ë“œ ìˆ˜
            print("\nğŸ“ˆ í…Œì´ë¸”ë³„ ë ˆì½”ë“œ ìˆ˜:")
            for table in tables:
                if table.table_type == 'BASE TABLE':
                    result = await conn.execute(
                        text(f"SELECT COUNT(*) FROM {table.table_name}")
                    )
                    count = result.scalar()
                    print(f"  - {table.table_name}: {count:,} ë ˆì½”ë“œ")
                    
    except Exception as e:
        print(f"âŒ í…Œì´ë¸” ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
    
    finally:
        await engine.dispose()

if __name__ == "__main__":
    asyncio.run(check_tables())
```

### Redis ì—°ê²° í…ŒìŠ¤íŠ¸
```python
# redis_check.py
import asyncio
import redis.asyncio as redis
from app.core.config import settings

async def check_redis():
    """Redis ì—°ê²° ë° ì •ë³´ í™•ì¸"""
    try:
        # ê° Redis DB í™•ì¸
        dbs = {
            "ì¼ë°˜ìš©": (settings.redis_url, 0),
            "ìºì‹œìš©": (settings.redis_cache_url, 1), 
            "Celery ë¸Œë¡œì»¤": (settings.celery_broker_url, 2),
            "Celery ê²°ê³¼": (settings.celery_result_backend, 3)
        }
        
        for db_name, (url, db_num) in dbs.items():
            client = redis.from_url(str(url))
            
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            await client.ping()
            print(f"âœ… {db_name} (DB {db_num}) ì—°ê²° ì„±ê³µ")
            
            # í‚¤ ê°œìˆ˜
            key_count = await client.dbsize()
            print(f"  ğŸ“Š í‚¤ ê°œìˆ˜: {key_count}")
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (DB 0ì—ì„œë§Œ)
            if db_num == 0:
                info = await client.info("memory")
                used_memory = info.get("used_memory_human", "N/A")
                print(f"  ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {used_memory}")
            
            await client.close()
            
    except Exception as e:
        print(f"âŒ Redis ì—°ê²° ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    asyncio.run(check_redis())
```

### ì‹¤ì œ ë°ì´í„° ìƒ˜í”Œ ì¡°íšŒ
```python
# data_sample.py
import asyncio
from sqlalchemy.ext.asyncio import create_async_engine
from sqlalchemy import text
from app.core.config import settings

async def show_sample_data():
    """ì‹¤ì œ ë°ì´í„° ìƒ˜í”Œ ì¡°íšŒ"""
    engine = create_async_engine(str(settings.database_url))
    
    try:
        async with engine.connect() as conn:
            # ë¦¬ì„œì¹˜ ì‘ì—… ìƒ˜í”Œ
            result = await conn.execute(text("""
                SELECT id, status, created_at, updated_at
                FROM research_jobs 
                ORDER BY created_at DESC 
                LIMIT 5
            """))
            
            jobs = result.fetchall()
            print("ğŸ” ìµœê·¼ ë¦¬ì„œì¹˜ ì‘ì—…:")
            for job in jobs:
                print(f"  - ID: {job.id}, ìƒíƒœ: {job.status}, ìƒì„±: {job.created_at}")
            
            # ë¦¬ì„œì¹˜ ì•„ì´í…œ ìƒ˜í”Œ
            result = await conn.execute(text("""
                SELECT product_name, category, price_exact, currency
                FROM research_items 
                ORDER BY created_at DESC 
                LIMIT 5
            """))
            
            items = result.fetchall()
            print("\nğŸ›ï¸ ìµœê·¼ ë¦¬ì„œì¹˜ ì•„ì´í…œ:")
            for item in items:
                print(f"  - {item.product_name} ({item.category}) - {item.price_exact:,}{item.currency}")
                
    except Exception as e:
        print(f"âŒ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
    
    finally:
        await engine.dispose()

if __name__ == "__main__":
    asyncio.run(show_sample_data())
```

## ğŸ”§ 4. Alembicìœ¼ë¡œ ìŠ¤í‚¤ë§ˆ ì •ë³´ í™•ì¸

### ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒíƒœ í™•ì¸
```bash
# í˜„ì¬ ë§ˆì´ê·¸ë ˆì´ì…˜ ë²„ì „
alembic current

# ë§ˆì´ê·¸ë ˆì´ì…˜ íˆìŠ¤í† ë¦¬
alembic history

# ë§ˆì´ê·¸ë ˆì´ì…˜ íˆìŠ¤í† ë¦¬ (ìì„¸íˆ)
alembic history -v

# ë‹¤ìŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì˜ˆìƒ
alembic show head

# íŠ¹ì • ë¦¬ë¹„ì „ ì •ë³´
alembic show <revision_id>
```

### ìŠ¤í‚¤ë§ˆ ìƒíƒœ í™•ì¸
```bash
# ìŠ¤í‚¤ë§ˆ ë¹„êµ (í˜„ì¬ DB vs ìµœì‹  ëª¨ë¸)
alembic check

# SQL ìƒì„± ë¯¸ë¦¬ë³´ê¸°
alembic upgrade head --sql

# ë§ˆì´ê·¸ë ˆì´ì…˜ ìë™ ìƒì„± ë¯¸ë¦¬ë³´ê¸°
alembic revision --autogenerate --message "test" --head-only
```

## ğŸš€ 5. Poetry Scripts í™œìš©

### ì»¤ìŠ¤í…€ DB ì²´í¬ ìŠ¤í¬ë¦½íŠ¸
```bash
# pyproject.tomlì— ì¶”ê°€í•  ìŠ¤í¬ë¦½íŠ¸
[tool.poetry.scripts]
db-info = "scripts.db_info:main"
db-check = "scripts.db_check:main"
db-sample = "scripts.db_sample:main"
```

### í†µí•© DB ì •ë³´ ìŠ¤í¬ë¦½íŠ¸
```python
# scripts/db_info.py
#!/usr/bin/env python3
"""ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´ í™•ì¸ ìŠ¤í¬ë¦½íŠ¸"""

import asyncio
import sys
from typing import Dict, Any
from sqlalchemy.ext.asyncio import create_async_engine
from sqlalchemy import text
import redis.asyncio as redis
from app.core.config import settings

class DatabaseInfo:
    def __init__(self):
        self.pg_engine = create_async_engine(str(settings.database_url))
    
    async def check_postgresql(self) -> Dict[str, Any]:
        """PostgreSQL ì •ë³´ ìˆ˜ì§‘"""
        try:
            async with self.pg_engine.connect() as conn:
                # ê¸°ë³¸ ì •ë³´
                result = await conn.execute(text("SELECT version()"))
                version = result.scalar()
                
                result = await conn.execute(text("""
                    SELECT 
                        current_database() as db_name,
                        current_user as user_name,
                        pg_size_pretty(pg_database_size(current_database())) as size
                """))
                info = result.fetchone()
                
                # í…Œì´ë¸” ì •ë³´
                result = await conn.execute(text("""
                    SELECT COUNT(*) as table_count
                    FROM information_schema.tables 
                    WHERE table_schema = 'public'
                """))
                table_count = result.scalar()
                
                # í™œì„± ì—°ê²° ìˆ˜
                result = await conn.execute(text("""
                    SELECT COUNT(*) as active_connections
                    FROM pg_stat_activity 
                    WHERE datname = current_database()
                """))
                connections = result.scalar()
                
                return {
                    "status": "âœ… ì—°ê²°ë¨",
                    "version": version.split()[0:2],
                    "database": info.db_name,
                    "user": info.user_name,
                    "size": info.size,
                    "tables": table_count,
                    "connections": connections
                }
                
        except Exception as e:
            return {
                "status": "âŒ ì—°ê²° ì‹¤íŒ¨",
                "error": str(e)
            }
    
    async def check_redis(self) -> Dict[str, Any]:
        """Redis ì •ë³´ ìˆ˜ì§‘"""
        try:
            client = redis.from_url(str(settings.redis_url))
            
            await client.ping()
            info = await client.info()
            keyspace = await client.info("keyspace")
            
            await client.close()
            
            return {
                "status": "âœ… ì—°ê²°ë¨",
                "version": info.get("redis_version"),
                "memory": info.get("used_memory_human"),
                "databases": len(keyspace),
                "uptime": f"{info.get('uptime_in_seconds', 0) // 3600}ì‹œê°„"
            }
            
        except Exception as e:
            return {
                "status": "âŒ ì—°ê²° ì‹¤íŒ¨", 
                "error": str(e)
            }
    
    async def generate_report(self):
        """ì „ì²´ ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ ë³´ê³ ì„œ"""
        print("=" * 60)
        print("ğŸ—„ï¸  ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ ë³´ê³ ì„œ")
        print("=" * 60)
        
        # PostgreSQL ì •ë³´
        print("\nğŸ“Š PostgreSQL:")
        pg_info = await self.check_postgresql()
        for key, value in pg_info.items():
            if key != "version":
                print(f"  {key}: {value}")
            else:
                print(f"  version: {' '.join(value)}")
        
        # Redis ì •ë³´  
        print("\nğŸ”´ Redis:")
        redis_info = await self.check_redis()
        for key, value in redis_info.items():
            print(f"  {key}: {value}")
        
        # í™˜ê²½ ì •ë³´
        print(f"\nğŸ”§ ì„¤ì •:")
        print(f"  í™˜ê²½: {settings.app_env}")
        print(f"  ë””ë²„ê·¸: {settings.debug}")
        print(f"  API í”„ë¦¬í”½ìŠ¤: {settings.api_v1_prefix}")
        
        await self.pg_engine.dispose()

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    db_info = DatabaseInfo()
    await db_info.generate_report()

if __name__ == "__main__":
    asyncio.run(main())
```

## ğŸ“Š 6. í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ í™œìš©

### API í—¬ìŠ¤ì²´í¬ë¡œ DB ìƒíƒœ í™•ì¸
```bash
# ê¸°ë³¸ í—¬ìŠ¤ì²´í¬
curl -s http://localhost:8000/api/v1/health | jq

# ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœë§Œ
curl -s http://localhost:8000/api/v1/health | jq '.services.database'

# Redis ìƒíƒœë§Œ  
curl -s http://localhost:8000/api/v1/health | jq '.services.redis'
```

### jqë¥¼ ì´ìš©í•œ JSON íŒŒì‹±
```bash
# ì „ì²´ ìƒíƒœ ìš”ì•½
curl -s http://localhost:8000/api/v1/health | jq '.status'

# ì„œë¹„ìŠ¤ë³„ ì‘ë‹µì‹œê°„
curl -s http://localhost:8000/api/v1/health | jq '.services | to_entries[] | {name: .key, response_time: .value.response_time_ms}'

# ì—ëŸ¬ê°€ ìˆëŠ” ì„œë¹„ìŠ¤ë§Œ
curl -s http://localhost:8000/api/v1/health | jq '.services | to_entries[] | select(.value.status != "healthy")'
```

## ğŸ” 7. ê°œë°œ ì¤‘ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

### Docker Compose ë¡œê·¸ ëª¨ë‹ˆí„°ë§
```bash
# ëª¨ë“  ì„œë¹„ìŠ¤ ë¡œê·¸
docker-compose logs -f

# PostgreSQL ë¡œê·¸ë§Œ
docker-compose logs -f postgres

# Redis ë¡œê·¸ë§Œ
docker-compose logs -f redis

# ìµœê·¼ ë¡œê·¸ (ë§ˆì§€ë§‰ 100ì¤„)
docker-compose logs --tail=100 postgres
```

### ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸
```bash
# ëª¨ë“  ì»¨í…Œì´ë„ˆ ìƒíƒœ
docker-compose ps

# ìƒì„¸ ìƒíƒœ ì •ë³´
docker-compose ps --services --filter "status=running"

# ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
docker stats cp9_postgres cp9_redis

# ì»¨í…Œì´ë„ˆ ë‚´ë¶€ í”„ë¡œì„¸ìŠ¤
docker exec cp9_postgres ps aux
```

## ğŸ¯ 8. ë¬¸ì œ í•´ê²°ìš© ì§„ë‹¨ ëª…ë ¹ì–´

### ì—°ê²° ë¬¸ì œ ì§„ë‹¨
```bash
# ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸
telnet localhost 5432
nc -zv localhost 5432

# Docker ë„¤íŠ¸ì›Œí¬ í™•ì¸  
docker network ls
docker network inspect backend-python_default

# í¬íŠ¸ ì‚¬ìš© í™•ì¸
netstat -tulpn | grep :5432
lsof -i :5432  # Mac/Linux
```

### ì„±ëŠ¥ ì§„ë‹¨
```bash
# PostgreSQL í™œì„± ì¿¼ë¦¬
docker exec -it cp9_postgres psql -U postgres -d research_db -c "
SELECT pid, usename, application_name, client_addr, state, query 
FROM pg_stat_activity 
WHERE state = 'active';
"

# í…Œì´ë¸” ì ê¸ˆ í™•ì¸
docker exec -it cp9_postgres psql -U postgres -d research_db -c "
SELECT * FROM pg_locks WHERE NOT granted;
"

# Redis ëŠë¦° ë¡œê·¸
docker exec -it cp9_redis redis-cli SLOWLOG GET 10
```

## ğŸ“‹ 9. ì •ê¸° ì ê²€ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì¼ì¼ ì ê²€
```bash
#!/bin/bash
# daily_db_check.sh

echo "=== $(date) ë°ì´í„°ë² ì´ìŠ¤ ì¼ì¼ ì ê²€ ==="

# ì„œë¹„ìŠ¤ ìƒíƒœ
echo "1. ì„œë¹„ìŠ¤ ìƒíƒœ:"
docker-compose ps | grep -E "(postgres|redis)"

# í—¬ìŠ¤ì²´í¬
echo "2. API í—¬ìŠ¤ì²´í¬:"
curl -s http://localhost:8000/api/v1/health | jq '.services.database.status, .services.redis.status'

# ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰
echo "3. ë³¼ë¥¨ ì‚¬ìš©ëŸ‰:"
docker system df -v | grep -E "(postgres|redis)"

# ì—°ê²° ìˆ˜
echo "4. í™œì„± ì—°ê²°:"
docker exec cp9_postgres psql -U postgres -d research_db -t -c "
SELECT count(*) FROM pg_stat_activity WHERE datname = 'research_db';
"

echo "ì ê²€ ì™„ë£Œ"
```

### ì£¼ê°„ ì ê²€
```bash
#!/bin/bash
# weekly_db_check.sh

echo "=== $(date) ë°ì´í„°ë² ì´ìŠ¤ ì£¼ê°„ ì ê²€ ==="

# ë°ì´í„°ë² ì´ìŠ¤ í¬ê¸° ì¶”ì´
echo "1. ë°ì´í„°ë² ì´ìŠ¤ í¬ê¸°:"
poetry run python scripts/db_info.py

# í…Œì´ë¸”ë³„ ë°ì´í„° ì¦ê°€ìœ¨
echo "2. í…Œì´ë¸”ë³„ ë ˆì½”ë“œ ìˆ˜:"
docker exec cp9_postgres psql -U postgres -d research_db -c "
SELECT schemaname, tablename, n_live_tup as live_tuples
FROM pg_stat_user_tables 
ORDER BY n_live_tup DESC;
"

# ì¸ë±ìŠ¤ ì‚¬ìš©ë¥ 
echo "3. ì¸ë±ìŠ¤ íš¨ìœ¨ì„±:"
docker exec cp9_postgres psql -U postgres -d research_db -c "
SELECT schemaname, tablename, indexname, idx_scan, idx_tup_read, idx_tup_fetch
FROM pg_stat_user_indexes 
WHERE idx_scan > 0
ORDER BY idx_scan DESC;
"

# ë°±ì—… ìƒíƒœ (ì„¤ì •ëœ ê²½ìš°)
echo "4. ë°±ì—… ìƒíƒœ í™•ì¸ í•„ìš”"

echo "ì£¼ê°„ ì ê²€ ì™„ë£Œ"
```

ì´ ê°€ì´ë“œë¥¼ í†µí•´ ë°ì´í„°ë² ì´ìŠ¤ì˜ ëª¨ë“  ì •ë³´ë¥¼ ì²´ê³„ì ìœ¼ë¡œ í™•ì¸í•˜ê³  ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê° ë°©ë²•ì€ ìƒí™©ì— ë”°ë¼ ì„ íƒì ìœ¼ë¡œ ì‚¬ìš©í•˜ì‹œë©´ ë©ë‹ˆë‹¤.