# ğŸ”§ ì¼ë°˜ì ì¸ ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

ê°œë°œ ì¤‘ ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œë“¤ê³¼ í•´ê²° ë°©ë²•ì„ ì •ë¦¬í•œ ì¢…í•© ê°€ì´ë“œì…ë‹ˆë‹¤.

## ğŸš€ ê°œë°œ í™˜ê²½ ë¬¸ì œ

### Poetry ê´€ë ¨ ë¬¸ì œ

#### 1. Poetryê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ
**ì¦ìƒ**
```bash
poetry: command not found
```

**í•´ê²°ë°©ë²•**
```bash
# Poetry ì„¤ì¹˜
curl -sSL https://install.python-poetry.org | python3 -

# PATH ì„¤ì •
echo 'export PATH="$HOME/.local/bin:$PATH"' >> ~/.bashrc
source ~/.bashrc

# ì„¤ì¹˜ í™•ì¸
poetry --version
```

#### 2. ê°€ìƒí™˜ê²½ í™œì„±í™” ë¬¸ì œ
**ì¦ìƒ**
```bash
poetry: The poetry.lock file does not exist
```

**í•´ê²°ë°©ë²•**
```bash
# ì˜ì¡´ì„± ë‹¤ì‹œ ì„¤ì¹˜
poetry install

# ê°€ìƒí™˜ê²½ ì¬ìƒì„±
poetry env remove python
poetry install
poetry shell
```

#### 3. ì˜ì¡´ì„± ì¶©ëŒ
**ì¦ìƒ**
```bash
SolverProblemError: The current project's Python requirement (>=3.11) is not compatible with some of the required packages.
```

**í•´ê²°ë°©ë²•**
```bash
# Poetry ìºì‹œ ì •ë¦¬
poetry cache clear pypi --all

# lock íŒŒì¼ ì¬ìƒì„±
rm poetry.lock
poetry lock

# ì˜ì¡´ì„± ì¬ì„¤ì¹˜
poetry install
```

### Docker ê´€ë ¨ ë¬¸ì œ

#### 1. Docker ì„œë¹„ìŠ¤ ì‹œì‘ ì‹¤íŒ¨
**ì¦ìƒ**
```bash
ERROR: Couldn't connect to Docker daemon
```

**í•´ê²°ë°©ë²•**
```bash
# Docker Desktop ì‹¤í–‰ ìƒíƒœ í™•ì¸
docker --version

# Docker ë°ëª¬ ì¬ì‹œì‘ (Linux)
sudo systemctl restart docker

# Docker Desktop ì¬ì‹œì‘ (Windows/Mac)
# Docker Desktop ì•± ì¬ì‹œì‘
```

#### 2. í¬íŠ¸ ì¶©ëŒ ë¬¸ì œ
**ì¦ìƒ**
```bash
Error starting userland proxy: listen tcp4 0.0.0.0:5432: bind: address already in use
```

**í•´ê²°ë°©ë²•**
```bash
# í¬íŠ¸ ì‚¬ìš© í”„ë¡œì„¸ìŠ¤ í™•ì¸
netstat -tulpn | grep :5432
lsof -i :5432  # Mac/Linux

# í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
kill -9 <PID>

# ë˜ëŠ” ë‹¤ë¥¸ í¬íŠ¸ ì‚¬ìš© (docker-compose.yml ìˆ˜ì •)
ports:
  - "5433:5432"  # í˜¸ìŠ¤íŠ¸ í¬íŠ¸ë¥¼ 5433ìœ¼ë¡œ ë³€ê²½
```

#### 3. ë³¼ë¥¨ ê¶Œí•œ ë¬¸ì œ
**ì¦ìƒ**
```bash
Permission denied: '/var/lib/postgresql/data'
```

**í•´ê²°ë°©ë²•**
```bash
# ë³¼ë¥¨ ì‚­ì œ í›„ ì¬ìƒì„±
docker-compose down -v
docker-compose up -d

# ê¶Œí•œ ì„¤ì • (Linux)
sudo chown -R $(id -u):$(id -g) ./data/postgres
```

## ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ë¬¸ì œ

### ì—°ê²° ë¬¸ì œ

#### 1. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨
**ì¦ìƒ**
```bash
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost", port 5432 failed
```

**í•´ê²°ë°©ë²•**
```bash
# PostgreSQL ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸
docker-compose ps

# ì»¨í…Œì´ë„ˆ ë¡œê·¸ í™•ì¸
docker-compose logs postgres

# ì—°ê²° í…ŒìŠ¤íŠ¸
poetry run python -c "
from app.infra.db.session import get_engine
import asyncio

async def test():
    engine = get_engine()
    async with engine.connect() as conn:
        result = await conn.execute('SELECT 1')
        print('DB ì—°ê²° ì„±ê³µ!')

asyncio.run(test())
"
```

#### 2. í™˜ê²½ë³€ìˆ˜ ì¸ì‹ ë¬¸ì œ
**ì¦ìƒ**
```bash
KeyError: 'DATABASE_URL'
```

**í•´ê²°ë°©ë²•**
```bash
# .env íŒŒì¼ í™•ì¸
cat .env

# í™˜ê²½ë³€ìˆ˜ ì„¤ì • í™•ì¸
echo $DATABASE_URL

# Poetry shellì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
poetry shell
export DATABASE_URL=postgresql+asyncpg://user:password@localhost:5432/dbname

# ë˜ëŠ” .env íŒŒì¼ ìƒì„±
echo "DATABASE_URL=postgresql+asyncpg://postgres:postgres@localhost:5432/research_db" > .env
```

### ë§ˆì´ê·¸ë ˆì´ì…˜ ë¬¸ì œ

#### 1. Alembic ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨
**ì¦ìƒ**
```bash
alembic.util.exc.CommandError: Target database is not up to date.
```

**í•´ê²°ë°©ë²•**
```bash
# í˜„ì¬ ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒíƒœ í™•ì¸
alembic current

# ë§ˆì´ê·¸ë ˆì´ì…˜ íˆìŠ¤í† ë¦¬ í™•ì¸
alembic history

# ê°•ì œ ë§ˆì´ê·¸ë ˆì´ì…˜ (ì£¼ì˜: ë°ì´í„° ì†ì‹¤ ê°€ëŠ¥)
alembic stamp head
alembic upgrade head

# ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” í›„ ë§ˆì´ê·¸ë ˆì´ì…˜
docker-compose down -v
docker-compose up -d postgres
alembic upgrade head
```

#### 2. ë§ˆì´ê·¸ë ˆì´ì…˜ ì¶©ëŒ
**ì¦ìƒ**
```bash
alembic.util.exc.CommandError: Multiple heads are present
```

**í•´ê²°ë°©ë²•**
```bash
# ì¶©ëŒ í™•ì¸
alembic heads

# ë§ˆì´ê·¸ë ˆì´ì…˜ ë³‘í•©
alembic merge heads -m "merge migrations"

# ë³‘í•©ëœ ë§ˆì´ê·¸ë ˆì´ì…˜ ì ìš©
alembic upgrade head
```

## ğŸ”„ Redis ë° Celery ë¬¸ì œ

### Redis ì—°ê²° ë¬¸ì œ

#### 1. Redis ì—°ê²° ì‹¤íŒ¨
**ì¦ìƒ**
```bash
redis.exceptions.ConnectionError: Error 111 connecting to localhost:6379. Connection refused.
```

**í•´ê²°ë°©ë²•**
```bash
# Redis ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸
docker-compose ps redis

# Redis ì—°ê²° í…ŒìŠ¤íŠ¸
redis-cli ping
# ì˜ˆìƒ ì¶œë ¥: PONG

# ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘
docker-compose restart redis

# Redis ì»¨í…Œì´ë„ˆ ë¡œê·¸ í™•ì¸
docker-compose logs redis
```

### Celery ì›Œì»¤ ë¬¸ì œ

#### 1. Celery ì›Œì»¤ ì‹œì‘ ì‹¤íŒ¨
**ì¦ìƒ**
```bash
[ERROR/MainProcess] consumer: Cannot connect to redis://localhost:6379/0: Error 111 connecting to localhost:6379.
```

**í•´ê²°ë°©ë²•**
```bash
# Redis ì—°ê²° í™•ì¸ (ìœ„ Redis ì„¹ì…˜ ì°¸ì¡°)
redis-cli ping

# Celery ì„¤ì • í™•ì¸
poetry run python -c "
from app.infra.tasks.celery_app import app
print(app.conf.broker_url)
print(app.conf.result_backend)
"

# ì›Œì»¤ ì¬ì‹œì‘
pkill -f celery
celery -A app.infra.tasks.celery_app worker --loglevel=info
```

#### 2. íƒœìŠ¤í¬ ì‹¤í–‰ ì‹¤íŒ¨
**ì¦ìƒ**
```bash
[ERROR/ForkPoolWorker-1] Task app.infra.tasks.research_task[...] raised unexpected: ModuleNotFoundError('No module named app')
```

**í•´ê²°ë°©ë²•**
```bash
# PYTHONPATH ì„¤ì •
export PYTHONPATH="${PYTHONPATH}:$(pwd)"

# ë˜ëŠ” Poetry shellì—ì„œ ì‹¤í–‰
poetry shell
celery -A app.infra.tasks.celery_app worker --loglevel=info

# ì„¤ì • íŒŒì¼ í™•ì¸
cat app/infra/tasks/celery_app.py
```

## ğŸŒ API ë° ì™¸ë¶€ ì„œë¹„ìŠ¤ ë¬¸ì œ

### FastAPI ì„œë²„ ë¬¸ì œ

#### 1. ì„œë²„ ì‹œì‘ ì‹¤íŒ¨
**ì¦ìƒ**
```bash
ModuleNotFoundError: No module named 'app'
```

**í•´ê²°ë°©ë²•**
```bash
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í„°ë¦¬ì—ì„œ ì‹¤í–‰ í™•ì¸
pwd
ls -la  # app/ ë””ë ‰í„°ë¦¬ê°€ ìˆëŠ”ì§€ í™•ì¸

# Poetry shell í™œì„±í™”
poetry shell

# PYTHONPATH ì„¤ì •
export PYTHONPATH="${PYTHONPATH}:$(pwd)"

# ì„œë²„ ì‹¤í–‰
poetry run dev
```

#### 2. ìë™ ë¦¬ë¡œë“œ ë™ì‘ ì•ˆí•¨
**ì¦ìƒ**
ì½”ë“œ ë³€ê²½ ì‹œ ì„œë²„ê°€ ìë™ìœ¼ë¡œ ì¬ì‹œì‘ë˜ì§€ ì•ŠìŒ

**í•´ê²°ë°©ë²•**
```bash
# uvicorn ì§ì ‘ ì‹¤í–‰ìœ¼ë¡œ í™•ì¸
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# íŒŒì¼ ê¶Œí•œ í™•ì¸ (Linux/Mac)
chmod -R 755 app/

# íŒŒì¼ ì‹œìŠ¤í…œ ì´ë²¤íŠ¸ í™•ì¸
# watchdog ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
poetry show | grep watchdog
```

### Perplexity API ë¬¸ì œ

#### 1. API í‚¤ ì¸ì‹ ì•ˆë¨
**ì¦ìƒ**
```bash
KeyError: 'PERPLEXITY_API_KEY'
```

**í•´ê²°ë°©ë²•**
```bash
# í™˜ê²½ë³€ìˆ˜ ì„¤ì • í™•ì¸
echo $PERPLEXITY_API_KEY

# .env íŒŒì¼ì— ì¶”ê°€
echo "PERPLEXITY_API_KEY=your_api_key_here" >> .env

# Poetry shellì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
poetry shell
export PERPLEXITY_API_KEY=your_api_key_here
```

#### 2. API í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ
**ì¦ìƒ**
```bash
httpx.TimeoutException: timed out
```

**í•´ê²°ë°©ë²•**
```python
# íƒ€ì„ì•„ì›ƒ ì„¤ì • ì¦ê°€ (app/core/config.py)
REQUEST_TIMEOUT = 120  # ê¸°ë³¸ 60ì—ì„œ 120ìœ¼ë¡œ ì¦ê°€

# ì¬ì‹œë„ ë¡œì§ í™•ì¸
RETRY_MAX_ATTEMPTS = 3
```

## ğŸ§ª í…ŒìŠ¤íŠ¸ ê´€ë ¨ ë¬¸ì œ

### í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨

#### 1. í…ŒìŠ¤íŠ¸ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨
**ì¦ìƒ**
```bash
sqlalchemy.exc.OperationalError: (asyncpg.exceptions.InvalidCatalogNameError) database "test_db" does not exist
```

**í•´ê²°ë°©ë²•**
```bash
# í…ŒìŠ¤íŠ¸ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
docker exec -it backend-python_postgres_1 createdb -U postgres test_db

# ë˜ëŠ” PostgreSQL ì»¨í…Œì´ë„ˆì—ì„œ ì§ì ‘ ìƒì„±
docker exec -it backend-python_postgres_1 psql -U postgres -c "CREATE DATABASE test_db;"

# í…ŒìŠ¤íŠ¸ í™˜ê²½ë³€ìˆ˜ ì„¤ì •
export DATABASE_URL=postgresql+asyncpg://postgres:postgres@localhost:5432/test_db
```

#### 2. ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë¬¸ì œ
**ì¦ìƒ**
```bash
RuntimeError: There is no current event loop in thread
```

**í•´ê²°ë°©ë²•**
```python
# pytest-asyncio ì„¤ì¹˜ í™•ì¸
poetry add --dev pytest-asyncio

# pytest.ini ì„¤ì • í™•ì¸
[tool:pytest]
asyncio_mode = auto

# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ì— ë°ì½”ë ˆì´í„° ì¶”ê°€
@pytest.mark.asyncio
async def test_example():
    pass
```

## ğŸ“Š ì„±ëŠ¥ ë¬¸ì œ

### ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë†’ìŒ

#### 1. ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ì˜ì‹¬
**ì¦ìƒ**
ì‹œê°„ì´ ì§€ë‚ ìˆ˜ë¡ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ê³„ì† ì¦ê°€

**ì§„ë‹¨ë°©ë²•**
```bash
# í”„ë¡œì„¸ìŠ¤ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
ps aux | grep -E "(python|celery)"

# Python ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§
poetry add --dev memory-profiler
poetry run python -m memory_profiler app/main.py

# ê°ì²´ ì°¸ì¡° ì¶”ì 
import gc
print(len(gc.get_objects()))
```

**í•´ê²°ë°©ë²•**
```python
# ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ ì ì ˆí•œ ì¢…ë£Œ
async with get_db() as session:
    # ì‘ì—… ìˆ˜í–‰
    pass  # sessionì´ ìë™ìœ¼ë¡œ ì¢…ë£Œë¨

# ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬
def process_large_data():
    for chunk in chunks(data, chunk_size=1000):
        process_chunk(chunk)
        gc.collect()  # ëª…ì‹œì  ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
```

### ì‘ë‹µ ì‹œê°„ ëŠë¦¼

#### 1. API ì‘ë‹µ ì‹œê°„ ë¶„ì„
**ì§„ë‹¨ë°©ë²•**
```bash
# cURLë¡œ ì‘ë‹µ ì‹œê°„ ì¸¡ì •
curl -w "Time: %{time_total}s\n" -o /dev/null -s http://localhost:8000/api/v1/health

# Apache Benchë¡œ ë¶€í•˜ í…ŒìŠ¤íŠ¸
ab -n 100 -c 10 http://localhost:8000/api/v1/health
```

**í•´ê²°ë°©ë²•**
```python
# ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ìµœì í™”
# N+1 ì¿¼ë¦¬ ë¬¸ì œ í•´ê²°
from sqlalchemy.orm import joinedload

result = await session.execute(
    select(Model).options(joinedload(Model.related_field))
)

# ë¹„ë™ê¸° ì²˜ë¦¬ í™œìš©
import asyncio

async def process_multiple_items(items):
    tasks = [process_item(item) for item in items]
    return await asyncio.gather(*tasks)
```

## ğŸ”§ ìœ ì§€ë³´ìˆ˜ ë„êµ¬

### ë¡œê·¸ ë¶„ì„

#### ë¡œê·¸ ë ˆë²¨ ì¡°ì •
```bash
# ë””ë²„ê·¸ ë¡œê·¸ í™œì„±í™”
export LOG_LEVEL=DEBUG
poetry run dev

# íŠ¹ì • ëª¨ë“ˆë§Œ ë””ë²„ê·¸
export LOG_LEVEL=INFO
# ì½”ë“œì—ì„œ ë¡œê±° ì„¤ì • ë³€ê²½
import logging
logging.getLogger('app.infra.llm').setLevel(logging.DEBUG)
```

#### êµ¬ì¡°í™”ëœ ë¡œê¹… í™•ì¸
```python
# ë¡œê·¸ í¬ë§· í™•ì¸
import json
import logging

# ë¡œê·¸ë¥¼ JSONìœ¼ë¡œ íŒŒì‹±í•˜ì—¬ ë¶„ì„
with open('app.log') as f:
    for line in f:
        try:
            log_entry = json.loads(line)
            print(f"Level: {log_entry['level']}, Message: {log_entry['message']}")
        except json.JSONDecodeError:
            continue
```

### ê±´ê°• ìƒíƒœ ëª¨ë‹ˆí„°ë§

#### ì‹œìŠ¤í…œ ìƒíƒœ ìŠ¤í¬ë¦½íŠ¸
```bash
#!/bin/bash
# health_check.sh

echo "=== ì‹œìŠ¤í…œ ìƒíƒœ ì²´í¬ ==="

echo "1. API ì„œë²„ ìƒíƒœ:"
curl -s http://localhost:8000/api/v1/health | jq '.status'

echo "2. ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ:"
docker exec backend-python_postgres_1 pg_isready -U postgres

echo "3. Redis ìƒíƒœ:"
redis-cli ping

echo "4. í”„ë¡œì„¸ìŠ¤ ìƒíƒœ:"
ps aux | grep -E "(uvicorn|celery)" | grep -v grep

echo "5. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:"
free -h

echo "6. ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰:"
df -h
```

### ì •ê¸° ìœ ì§€ë³´ìˆ˜

#### ì£¼ê°„ ì²´í¬ë¦¬ìŠ¤íŠ¸
```bash
# 1. ë¡œê·¸ íŒŒì¼ ì •ë¦¬
find . -name "*.log" -mtime +7 -delete

# 2. Docker ì´ë¯¸ì§€ ì •ë¦¬
docker system prune -f

# 3. Poetry ìºì‹œ ì •ë¦¬
poetry cache clear pypi --all

# 4. í…ŒìŠ¤íŠ¸ ì‹¤í–‰
poetry run test

# 5. ë³´ì•ˆ ì·¨ì•½ì  ìŠ¤ìº”
poetry audit

# 6. ì˜ì¡´ì„± ì—…ë°ì´íŠ¸ í™•ì¸
poetry show --outdated
```

## ğŸ†˜ ê¸´ê¸‰ ìƒí™© ëŒ€ì‘

### ì„œë¹„ìŠ¤ ë‹¤ìš´ ì‹œ

#### ë¹ ë¥¸ ì¬ì‹œì‘ ì ˆì°¨
```bash
# 1. ì „ì²´ ì„œë¹„ìŠ¤ ì¢…ë£Œ
poetry run stop

# 2. Docker ì •ë¦¬
docker-compose down -v

# 3. ë¡œê·¸ ë°±ì—…
cp app.log app_$(date +%Y%m%d_%H%M%S).log

# 4. ì„œë¹„ìŠ¤ ì¬ì‹œì‘
poetry run setup
poetry run dev

# 5. ìƒíƒœ í™•ì¸
curl http://localhost:8000/api/v1/health
```

### ë°ì´í„°ë² ì´ìŠ¤ ì†ìƒ ì‹œ

#### ë³µêµ¬ ì ˆì°¨
```bash
# 1. ë°±ì—…ì—ì„œ ë³µêµ¬ (ë°±ì—…ì´ ìˆëŠ” ê²½ìš°)
docker exec -i backend-python_postgres_1 psql -U postgres -d research_db < backup.sql

# 2. ë§ˆì´ê·¸ë ˆì´ì…˜ìœ¼ë¡œ ì¬êµ¬ì¶•
docker-compose down -v
docker-compose up -d postgres
sleep 10
alembic upgrade head

# 3. ë°ì´í„° ì¼ê´€ì„± ê²€ì‚¬
poetry run python -c "
from app.infra.db.session import get_engine
import asyncio

async def check():
    engine = get_engine()
    async with engine.connect() as conn:
        result = await conn.execute('SELECT COUNT(*) FROM research_jobs')
        print(f'Jobs count: {result.scalar()}')

asyncio.run(check())
"
```

ì´ ê°€ì´ë“œë¥¼ ì°¸ì¡°í•˜ì—¬ ëŒ€ë¶€ë¶„ì˜ ì¼ë°˜ì ì¸ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¬¸ì œê°€ ì§€ì†ë˜ë©´ GitHub Issuesì— ìƒì„¸í•œ ë¡œê·¸ì™€ í•¨ê»˜ ë¬¸ì˜í•´ ì£¼ì„¸ìš”.